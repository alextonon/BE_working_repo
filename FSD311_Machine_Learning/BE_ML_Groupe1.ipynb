{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2641a4",
   "metadata": {},
   "source": [
    "# BE - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccda26",
   "metadata": {},
   "source": [
    "### Données\n",
    "\n",
    "Le dataset est un dataset UCML, on pourrait utiliser le module *ucmlrepo* et la methode *fetch_ucirepo* associée, mais le chargement des données est long (~2 minutes). On privilégiera donc un téléchargement et des méthodes de lecture manuelles, les données ne faisant que 600Ko\n",
    "\n",
    "Le dataset a été construit pour prédire la target *income* qui comporte deux valeurs (>50K, <=50K) à partir de 14 features. Cette construction en \"classes\" nous impose de travailler avec des classifiers plutôt qu'avec des regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bb107c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = pd.read_table(\"data/adult.names\", sep=\":\", skiprows=96, header=None)[0].tolist()\n",
    "names.append(\"income\") # La target n'est pas dans le fichier des noms\n",
    "adult = pd.read_csv(\"data/adult.data\", sep=\", \", names=names, engine='python', index_col=False) # Le engine permet juste d'éviter un warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02c7a7",
   "metadata": {},
   "source": [
    "### Nettoyage et Pre processing\n",
    "\n",
    "Avant de mettre en place des modèles il nous fait nettoyer un peu les données pour pouvoir les exploiter. En particulier, nous aimerions supprimer les *valuers manquantes* ainsi que les *outliers*. En mettant en place les algo classiques, nous nous sommes vite rendu compte d'un problème : la plupart des catégories sont encodées sous forme de texte. Ainsi les algo ne peuvent fonctionner. C'est la raison pour laquelle nous allons mettre en place cette pipeline de nettoyage :\n",
    "- **Suppression des #NA :** Les NA étant encodés par des \"?\" (il n'y a pas de NA sinon) nous allons supprimer chaque lignes qui en comportent\n",
    "- **Encodage des colonnes :** Nous allons encoder chaque colonnes de la façon suivante : chaque valeur unique se voit attribuer un entier. Nous n'avons que peu de recul pour l'instant et ne savons pas si c'est pertinent\n",
    "- **Normalisation :** POur contrer l'effet du nombre e colonnes, nous allons normaliser celles ci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass : 1836 NA\n",
      "occupation : 1843 NA\n",
      "native-country : 583 NA\n"
     ]
    }
   ],
   "source": [
    "#### Suppression des NA ####\n",
    "adult.replace(\"?\", pd.NA, inplace=True)  # Les NA sont codés par des \"?\"\n",
    "\n",
    "for key in adult.keys():\n",
    "    n_na = adult[key].isna().sum()\n",
    "    if n_na > 0:\n",
    "        print(f\"{key} : {n_na} NA\")\n",
    "\n",
    "adult.dropna(inplace=True)  # On supprime les lignes avec NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19099d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Encodage des colonnes ####\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for column in adult.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    adult[column] = le.fit_transform(adult[column])\n",
    "    label_encoders[column] = le"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
